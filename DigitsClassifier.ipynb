{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Working with Image Data\n",
    "\n",
    "Data sets are in - [Datasets](https://scikit-learn.org/stable/datasets.html)\n",
    "\n",
    "Load Digits from SKLEARN.DATASETs returns [hand written digits dataset ](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from \n",
    "digits_data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = digits_data['target']\n",
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(digits_data['data'])\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = data.iloc[0]\n",
    "np_image = first_image.values\n",
    "np_image = np_image.reshape(8,8)\n",
    "\n",
    "plt.imshow(np_image, cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 4)\n",
    "\n",
    "axarr[0, 0].imshow(data.iloc[0].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 1].imshow(data.iloc[99].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 2].imshow(data.iloc[199].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 3].imshow(data.iloc[299].values.reshape(8,8), cmap='gray_r')\n",
    "\n",
    "axarr[1, 0].imshow(data.iloc[999].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 1].imshow(data.iloc[1099].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 2].imshow(data.iloc[1199].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 3].imshow(data.iloc[1299].values.reshape(8,8), cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split up data into train and test sets\n",
    "- Setup a pipeline for testing and training k-nn models.\n",
    "\n",
    "    - Write a function named train() that uses KNeighborsClassifer for training k-nearest neighbors models\n",
    "    - Write a function named test() that tests the model.\n",
    "    - Write a function named cross_validate() that performs 4-fold cross validation using train() and test().\n",
    "\n",
    "- Experiment with different values for k and plot the resulting classification accuracies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_knn(nneighbors, train_features, train_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors = nneighbors)\n",
    "    knn.fit(train_features, train_labels)\n",
    "    return knn\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate(k):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "        \n",
    "        model = train_knn(k, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "        \n",
    "    return fold_accuracies\n",
    "        \n",
    "knn_one_accuracies = cross_validate(1)\n",
    "np.mean(knn_one_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(1,10))\n",
    "k_overall_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    k_accuracies = cross_validate(k)\n",
    "    k_mean_accuracy = np.mean(k_accuracies)\n",
    "    k_overall_accuracies.append(k_mean_accuracy)\n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. k\")\n",
    "plt.plot(k_values, k_overall_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with One Hidden Layer\n",
    "\n",
    "Using 4-fold cross validation:\n",
    "\n",
    " - Train and test a neural network model using a single hidden layer of 8 neurons.\n",
    " - Train and test a neural network model using a single hidden layer of 16 neurons.\n",
    " - Train and test a neural network model using a single hidden layer of 32 neurons.\n",
    " - Train and test a neural network model using a single hidden layer of 64 neurons.\n",
    " - Train and test a neural network model using a single hidden layer of 128 neurons.\n",
    " - Train and test a neural network model using a single hidden layer of 256 neurons.\n",
    "\n",
    "Create a new Markdown cell summarizing what you saw.\n",
    "\n",
    " - Rank the performance of the models by the overall accuracies.\n",
    " - Which models, if any, start to overfit?\n",
    " - For each model, you could compute and visualize the performance for both the train and test sets to understand how they diverged. Models that overfit tend to perform well on the train set but poorly on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_nn(neuron_arch, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_arch)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate(neuron_arch):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2, shuffle=True)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "       \n",
    "        model = train_nn(neuron_arch, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_one_neurons = [\n",
    "    (8,),\n",
    "    (16,),\n",
    "    (32,),\n",
    "    (64,),\n",
    "    (128,),\n",
    "    (256,)\n",
    "]\n",
    "nn_one_accuracies = []\n",
    "\n",
    "for n in nn_one_neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_one_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Single Hidden Layer\")\n",
    "\n",
    "x = [i[0] for i in nn_one_neurons]\n",
    "plt.plot(x, nn_one_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "It looks like adding more neurons to the single hidden layer improved simple accuracy to approximately 97%. Simple accuracy computes the number of correct classifications the model made, but doesn't tell us anything about false or true positives or false or true negatives.\n",
    "\n",
    "Given that k-nearest neighbors achieved approximately 98% accuracy, there doesn't seem to be any advantages to using a single hidden layer neural network for this problem.\n",
    "\n",
    "# Neural Network with Two Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_two_neurons = [\n",
    "    (64,64),\n",
    "    (128, 128),\n",
    "    (256, 256)\n",
    "]\n",
    "nn_two_accuracies = []\n",
    "\n",
    "for n in nn_two_neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_two_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Two Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in nn_two_neurons]\n",
    "plt.plot(x, nn_two_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_two_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Using two hidden layers improved our simple accuracy to 98%. While, traditionally, we might worry about overfitting, using four-fold cross validation also gives us a bit more assurance that the model is generalizing to achieve the extra 1% in simple accuracy over the single hidden layer networks we tried earlier.\n",
    "\n",
    "# Neural Network with Three Hidden Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_nn(neuron_arch, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_arch)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate_six(neuron_arch):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 6, random_state=2, shuffle=True)\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "       \n",
    "        model = train_nn(neuron_arch, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "        \n",
    "    return fold_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_three_neurons = [\n",
    "    (10, 10, 10),\n",
    "    (64, 64, 64),\n",
    "    (128, 128, 128)\n",
    "]\n",
    "\n",
    "nn_three_accuracies = []\n",
    "\n",
    "for n in nn_three_neurons:\n",
    "    nn_accuracies = cross_validate_six(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_three_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Three Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in nn_three_neurons]\n",
    "plt.plot(x, nn_three_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_three_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using three hidden layers returned a simple accuracy of nearly 98%, even with six-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
